{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfjNQBOtFpkTYOVb+w0FKM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKH-ML/python/blob/main/6_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80_%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1_%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 선형 회귀 (Linear Regression)\n",
        "\n",
        "## 개념\n",
        "\n",
        "선형 회귀는 입력 변수 $\\mathbf{x}$와 출력 변수 $y$ 사이의 선형 관계를 모델링하는 기법입니다.\n",
        "\n",
        "예측 식:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b\n",
        "$$\n",
        "\n",
        "여기서,  \n",
        "$\\hat{y}$ 는 예측값,  \n",
        "$\\mathbf{w}$ 는 가중치 벡터,  \n",
        "$b$ 는 절편 (bias),  \n",
        "$\\mathbf{x}$ 는 입력 벡터입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 손실 함수 (Mean Squared Error)\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\hat{y}_i - y_i \\right)^2\n",
        "$$\n",
        "\n",
        "이는 예측값 $\\hat{y}$와 실제값 $y$의 차이를 제곱하여 평균한 값입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 목적\n",
        "\n",
        "이 손실 $\\mathcal{L}$을 최소화하는 $\\mathbf{w}, b$를 찾는 것이 목표입니다.\n",
        "\n",
        "---\n",
        "\n",
        "# 2. 로지스틱 회귀 (Logistic Regression)\n",
        "\n",
        "## 개념\n",
        "\n",
        "로지스틱 회귀는 **이진 분류** 문제에 사용됩니다.  \n",
        "선형 회귀 결과를 시그모이드 함수를 통해 0~1 사이의 확률로 변환합니다.\n",
        "\n",
        "예측 식:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)\n",
        "$$\n",
        "\n",
        "시그모이드 함수는 다음과 같습니다:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "여기서,  \n",
        "$\\hat{y}$ 는 클래스 1일 확률을 의미하며,  \n",
        "$\\sigma$ 는 시그모이드 함수입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 손실 함수 (Binary Cross-Entropy)\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log \\hat{y}_i + (1 - y_i) \\log (1 - \\hat{y}_i) \\right]\n",
        "$$\n",
        "\n",
        "이 손실 함수는 실제 클래스 $y_i$와 예측 확률 $\\hat{y}_i$ 사이의 오차를 계산합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 목적\n",
        "\n",
        "로지스틱 회귀의 목적은, 예측 확률 $\\hat{y}$와 실제 클래스 $y$ 사이의 차이를 최소화하는 파라미터 $\\mathbf{w}, b$를 찾는 것입니다.\n"
      ],
      "metadata": {
        "id": "DfwMWvTnExDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 선형 회귀 및 로지스틱 회귀 실습 코드 설명\n",
        "\n",
        "## 1. 선형 회귀 (Linear Regression)\n",
        "\n",
        "### 데이터 생성\n",
        "\n",
        "```python\n",
        "X_lin = 2 * np.random.rand(100, 1)\n",
        "y_lin = 4 + 3 * X_lin + np.random.randn(100, 1)\n",
        "```\n",
        "\n",
        "- 입력값 $x$는 0~2 사이의 값 100개를 생성합니다.\n",
        "- 실제 출력값 $y$는 $y = 4 + 3x + \\epsilon$ 형태이며, 약간의 노이즈가 추가됩니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 선형 회귀 함수 정의\n",
        "\n",
        "```python\n",
        "def linear_regression(X, y, lr=0.1, epochs=1000):\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    w = np.random.randn(2, 1)\n",
        "    for _ in range(epochs):\n",
        "        gradients = 2 / X.shape[0] * X_b.T.dot(X_b.dot(w) - y)\n",
        "        w -= lr * gradients\n",
        "    return w\n",
        "```\n",
        "\n",
        "- $X$에 bias 항을 추가하여 $X_b = [1, x]$ 형태로 만듭니다.\n",
        "- 임의로 초기화된 가중치 $w$를 사용해 경사 하강법으로 학습합니다.\n",
        "- 손실 함수는 평균 제곱 오차 (MSE)를 사용하며, 그에 따른 gradient를 직접 계산합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 예측 및 시각화\n",
        "\n",
        "```python\n",
        "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "X_test_b = np.c_[np.ones((100, 1)), X_test]\n",
        "y_pred_lin = X_test_b.dot(w_lin)\n",
        "```\n",
        "\n",
        "- 테스트용 입력 $x$ 값 100개를 생성하고 예측값 $\\hat{y}$를 계산합니다.\n",
        "\n",
        "시각화에는 Plotly를 사용해 실제 데이터 (산점도)와 예측 직선 (선 그래프)를 함께 표시합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 로지스틱 회귀 (Logistic Regression)\n",
        "\n",
        "### 데이터 생성\n",
        "\n",
        "```python\n",
        "X_log, y_log = make_classification(...)\n",
        "```\n",
        "\n",
        "- 사이킷런 `make_classification`을 이용해 1차원 분류용 샘플 데이터를 생성합니다.\n",
        "- $X$는 하나의 특성(feature)을 가지며, $y$는 0 또는 1 클래스입니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 시그모이드 함수 정의\n",
        "\n",
        "```python\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "```\n",
        "\n",
        "- 시그모이드 함수는 임의의 입력 $z$를 (0, 1) 사이의 확률 값으로 변환합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 로지스틱 회귀 함수 정의\n",
        "\n",
        "```python\n",
        "def logistic_regression(X, y, lr=0.1, epochs=1000):\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    w = np.random.randn(X_b.shape[1], 1)\n",
        "    y = y.reshape(-1, 1)\n",
        "    for _ in range(epochs):\n",
        "        z = X_b.dot(w)\n",
        "        h = sigmoid(z)\n",
        "        gradients = 1 / X.shape[0] * X_b.T.dot(h - y)\n",
        "        w -= lr * gradients\n",
        "    return w\n",
        "```\n",
        "\n",
        "- 선형 조합 $z = Xw$에 시그모이드 함수를 적용하여 예측 확률 $\\hat{y}$를 얻습니다.\n",
        "- 손실 함수는 Binary Cross-Entropy이며, 이를 직접 미분한 식으로 gradient를 계산합니다.\n",
        "- 경사 하강법으로 파라미터 $w$를 업데이트합니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 예측 및 시각화\n",
        "\n",
        "```python\n",
        "y_prob = sigmoid(X_range_b.dot(w_log))\n",
        "```\n",
        "\n",
        "- 테스트용 $x$ 값에 대해 확률 예측을 수행합니다.\n",
        "- Plotly로 실제 클래스 (0 또는 1)과 예측된 확률 곡선을 함께 시각화합니다.\n"
      ],
      "metadata": {
        "id": "SMxc8jNSHwVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 머신러닝 핵심 개념 설명\n",
        "\n",
        "---\n",
        "\n",
        "## 1. 가중치 (Weight)\n",
        "\n",
        "가중치는 입력 데이터의 중요도를 조절하는 **계수**입니다.  \n",
        "선형 회귀나 신경망에서 입력 벡터 $\\mathbf{x}$의 각 요소에 곱해지는 값입니다.\n",
        "\n",
        "예:  \n",
        "$$\n",
        "\\hat{y} = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b = \\mathbf{w}^\\top \\mathbf{x} + b\n",
        "$$\n",
        "\n",
        "가중치는 학습을 통해 조정되며, 예측의 정확도를 높이기 위한 핵심 변수입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 바이어스 (Bias)\n",
        "\n",
        "바이어스는 예측 함수에 추가되는 **상수항**입니다.  \n",
        "모델이 원점을 기준으로만 회전하거나 이동하는 것을 방지하여, **데이터의 분포를 더 잘 맞출 수 있게** 해줍니다.\n",
        "\n",
        "예:  \n",
        "$$\n",
        "\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b\n",
        "$$\n",
        "\n",
        "여기서 $b$는 바이어스 항입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. 손실 함수 (Loss Function)\n",
        "\n",
        "손실 함수는 **모델이 예측한 값 $\\hat{y}$와 실제 정답 $y$ 사이의 차이**를 수치화하는 함수입니다.  \n",
        "모델이 얼마나 잘 작동하는지를 측정하며, 학습의 목표는 손실 함수를 **최소화**하는 것입니다.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. 평균 제곱 오차 (MSE, Mean Squared Error)\n",
        "\n",
        "주로 회귀 문제에서 사용되는 손실 함수입니다.  \n",
        "예측값과 실제값의 차이를 제곱한 뒤 평균을 구합니다.\n",
        "\n",
        "수식:  \n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "특징:\n",
        "- 값이 클수록 오차가 큼을 의미\n",
        "- 미분 가능하므로 경사 하강법에 적합\n",
        "- 이상치에 민감함 (제곱하기 때문에)\n",
        "\n",
        "---\n",
        "\n",
        "## 5. 이진 교차 엔트로피 (Binary Cross-Entropy)\n",
        "\n",
        "로지스틱 회귀 및 이진 분류 문제에서 주로 사용됩니다.  \n",
        "예측된 확률 $\\hat{y}$가 실제 클래스 $y$와 얼마나 일치하는지를 측정합니다.\n",
        "\n",
        "수식:  \n",
        "$$\n",
        "\\text{BCE} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
        "$$\n",
        "\n",
        "특징:\n",
        "- 확률 예측값 $\\hat{y}_i$가 실제 $y_i$와 가까울수록 손실이 작아짐\n",
        "- $y_i = 1$일 때는 $\\log(\\hat{y}_i)$, $y_i = 0$일 때는 $\\log(1 - \\hat{y}_i)$만 작동\n",
        "- 분류에서 성능 측정에 효과적\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 경사 하강법 (Gradient Descent)\n",
        "\n",
        "손실 함수를 최소화하기 위해 사용되는 **최적화 알고리즘**입니다.  \n",
        "함수의 기울기(gradient)를 따라 **조금씩 파라미터를 업데이트**해 나갑니다.\n",
        "\n",
        "업데이트 식 (예: MSE 기준):  \n",
        "$$\n",
        "\\mathbf{w} := \\mathbf{w} - \\eta \\cdot \\nabla_{\\mathbf{w}} \\mathcal{L}\n",
        "$$\n",
        "\n",
        "- $\\eta$는 학습률 (learning rate)로, 얼마나 크게 이동할지를 조절\n",
        "- $\\nabla_{\\mathbf{w}} \\mathcal{L}$는 손실 함수 $\\mathcal{L}$에 대한 가중치 $\\mathbf{w}$의 기울기\n",
        "\n",
        "특징:\n",
        "- 손실이 줄어드는 방향으로 이동\n",
        "- 너무 크게 이동하면 발산하고, 너무 작으면 느리게 수렴\n",
        "\n",
        "---\n",
        "\n",
        "## 7. 시그모이드 함수 (Sigmoid Function)\n",
        "\n",
        "시그모이드는 입력을 **0과 1 사이의 값**으로 압축하는 함수입니다.  \n",
        "로지스틱 회귀에서 확률을 계산할 때 사용됩니다.\n",
        "\n",
        "수식:  \n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "특징:\n",
        "- $z \\to \\infty$일 때 $\\sigma(z) \\to 1$, $z \\to -\\infty$일 때 $\\sigma(z) \\to 0$\n",
        "- 미분 가능\n",
        "- 로지스틱 회귀에서 예측 확률로 해석됨\n",
        "\n",
        "예:  \n",
        "입력 $z = \\mathbf{w}^\\top \\mathbf{x} + b$ 를 시그모이드에 통과시키면 예측 확률 $\\hat{y}$를 얻음:\n",
        "$$\n",
        "\\hat{y} = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "ztj12ETkKG1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 8. 하이퍼파라미터 (Hyperparameter)\n",
        "\n",
        "하이퍼파라미터는 **모델이 학습되기 전에 사용자가 직접 설정하는 변수**입니다.  \n",
        "학습 과정에서 자동으로 업데이트되지 않으며, 모델의 성능에 큰 영향을 미칩니다.\n",
        "\n",
        "예시:\n",
        "- 학습률 (learning rate, $\\eta$)\n",
        "- 반복 횟수 (epochs)\n",
        "- 배치 크기 (batch size)\n",
        "- 정규화 계수 (L2 패널티 등)\n",
        "- 은닉층의 수 및 뉴런 개수\n",
        "- 초기 가중치 범위\n",
        "\n",
        "하이퍼파라미터는 주로 **실험과 검증**을 통해 최적화됩니다.  \n",
        "이를 **하이퍼파라미터 튜닝**이라고 합니다 (ex: grid search, random search, Bayesian optimization).\n",
        "\n",
        "---\n",
        "\n",
        "## 9. 활성화 함수 (Activation Function)\n",
        "\n",
        "활성화 함수는 뉴런의 **출력을 비선형적으로 변환**하여, **복잡한 함수나 분류 경계**를 학습할 수 있도록 도와줍니다.\n",
        "\n",
        "대표적인 활성화 함수:\n",
        "\n",
        "1. **시그모이드 (Sigmoid)**  \n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}} \\quad \\text{(0과 1 사이의 값 출력)}\n",
        "   $$\n",
        "\n",
        "2. **하이퍼볼릭 탄젠트 (Tanh)**  \n",
        "   $$\n",
        "   \\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} \\quad \\text{(-1과 1 사이 출력)}\n",
        "   $$\n",
        "\n",
        "3. **ReLU (Rectified Linear Unit)**  \n",
        "   $$\n",
        "   \\text{ReLU}(z) = \\max(0, z)\n",
        "   $$\n",
        "\n",
        "특징 요약:\n",
        "\n",
        "| 함수 | 출력 범위 | 장점 | 단점 |\n",
        "|------|-----------|------|------|\n",
        "| Sigmoid | (0, 1) | 확률 표현 적합 | 기울기 소실 문제 |\n",
        "| Tanh | (-1, 1) | 중심이 0이라 학습 빠름 | 여전히 기울기 소실 |\n",
        "| ReLU | [0, ∞) | 계산 효율, 빠른 수렴 | 음수 영역에서 죽은 뉴런 발생 가능 |\n",
        "\n",
        "신경망에서는 보통 **은닉층에는 ReLU**, **출력층에는 Sigmoid(이진), Softmax(다중 분류)** 를 사용합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "OYMN3TDULoYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 10. 정규화 (Normalization)\n",
        "\n",
        "정규화는 입력 데이터를 일정한 범위로 스케일링하는 전처리 과정입니다.  \n",
        "특히 머신러닝에서는 서로 다른 스케일을 가진 피처들이 모델에 영향을 끼치지 않도록 **균형을 맞추기 위해 필수적인 작업**입니다.\n",
        "\n",
        "### 주요 기법\n",
        "\n",
        "1. **Min-Max 정규화**\n",
        "   $$\n",
        "   x_{\\text{norm}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\n",
        "   $$\n",
        "   - 모든 데이터를 [0, 1] 범위로 변환\n",
        "\n",
        "2. **Z-정규화 (표준화, Standardization)**\n",
        "   $$\n",
        "   x_{\\text{std}} = \\frac{x - \\mu}{\\sigma}\n",
        "   $$\n",
        "   - 평균이 0, 표준편차가 1인 정규 분포로 변환\n",
        "   - 이상치에 더 견고함\n",
        "\n",
        "정규화를 하지 않으면 **특정 변수의 스케일이 너무 커서** 모델이 제대로 학습되지 않거나, **경사 하강법의 수렴 속도가 느려질 수 있습니다.**\n",
        "\n",
        "---\n",
        "\n",
        "## 11. 오버피팅 / 언더피팅\n",
        "\n",
        "모델이 **학습 데이터에 대해 과도하게 적응하거나** (Overfitting), **충분히 학습하지 못하는** (Underfitting) 상황을 의미합니다.\n",
        "\n",
        "### 오버피팅 (Overfitting)\n",
        "\n",
        "- 학습 데이터에는 매우 높은 정확도를 보이지만, 테스트 데이터에는 성능이 낮아짐\n",
        "- 모델이 **데이터의 잡음(noise)까지 외워버림**\n",
        "- 원인: 복잡한 모델, 학습 시간 과다, 데이터 부족\n",
        "\n",
        "### 언더피팅 (Underfitting)\n",
        "\n",
        "- 학습 데이터조차 제대로 학습하지 못함\n",
        "- 모델이 **너무 단순하거나**, 학습을 충분히 하지 않음\n",
        "- 원인: 너무 작은 모델, 너무 짧은 학습 시간, 너무 큰 학습률\n",
        "\n",
        "### 비교 요약\n",
        "\n",
        "| 구분 | 오버피팅 | 언더피팅 |\n",
        "|------|----------|-----------|\n",
        "| 원인 | 복잡한 모델, 학습 과다 | 단순한 모델, 학습 부족 |\n",
        "| 특징 | 훈련 정확도↑, 테스트 정확도↓ | 훈련/테스트 모두 정확도 낮음 |\n",
        "| 해결책 | 드롭아웃, 정규화, 더 많은 데이터 | 모델 복잡도 증가, 학습 충분히 |\n",
        "\n"
      ],
      "metadata": {
        "id": "VehX2O9QMGLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 12. 추가로 알아보면 좋은 키워드 목록\n",
        "\n",
        "머신러닝/딥러닝 모델을 효과적으로 학습하고 일반화 성능을 향상시키기 위해, 아래 개념들도 함께 학습하는 것이 좋습니다.\n",
        "\n",
        "| 키워드 | 설명 |\n",
        "|--------|------|\n",
        "| **Dropout** | 학습 중 일부 뉴런을 무작위로 비활성화하여 과적합을 방지 |\n",
        "| **Batch Normalization** | 각 미니배치마다 입력을 정규화하여 학습을 안정화하고 빠르게 수렴 |\n",
        "| **Weight Initialization (Xavier, He)** | 가중치 초기화 방법으로, 적절한 분산을 통해 학습 효율 개선 |\n",
        "| **Optimizers (SGD, Adam, RMSprop 등)** | 경사 하강법의 변형으로, 학습률 조절 및 모멘텀을 포함한 최적화 방법 |\n",
        "| **Learning Rate Scheduler** | 학습 도중 학습률을 동적으로 조정하여 손실 수렴을 유도 |\n",
        "| **Early Stopping** | 검증 데이터 손실이 더 이상 감소하지 않으면 학습을 조기 종료 |\n",
        "| **Data Augmentation** | 훈련 데이터를 회전, 이동, 왜곡 등을 통해 늘려서 일반화 성능을 향상 |\n",
        "| **Softmax 함수** | 다중 클래스 분류에서 각 클래스에 대한 확률 출력을 생성하는 함수 |\n",
        "| **Cross-validation (교차 검증)** | 데이터를 여러 조각으로 나누어 모델의 일반화 성능을 평가하는 기법 |\n",
        "| **L1/L2 정규화** | 가중치에 패널티를 주어 과적합을 방지 (L1은 희소성, L2는 작게 유지) |\n",
        "| **모델 저장 및 불러오기** | 학습된 모델을 파일로 저장하고 재사용하는 방법 (Pickle, Torch 등) |\n",
        "\n",
        "---\n",
        "\n",
        "이 키워드들은 중급 이상으로 나아갈 때 매우 중요한 개념들로, 각 용어에 대해 실습과 함께 학습하는 것을 권장합니다.\n"
      ],
      "metadata": {
        "id": "HV8_eBW5Mi3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear & Logistic Regression 구현 (NumPy + Plotly)\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# 선형 회귀용 샘플 데이터 생성\n",
        "np.random.seed(0)\n",
        "X_lin = 2 * np.random.rand(100, 1)\n",
        "y_lin = 4 + 3 * X_lin + np.random.randn(100, 1)\n",
        "\n",
        "# 선형 회귀 학습 함수\n",
        "def linear_regression(X, y, lr=0.1, epochs=1000):\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    w = np.random.randn(2, 1)\n",
        "    for _ in range(epochs):\n",
        "        gradients = 2 / X.shape[0] * X_b.T.dot(X_b.dot(w) - y)\n",
        "        w -= lr * gradients\n",
        "    return w\n",
        "\n",
        "# 학습 및 예측\n",
        "w_lin = linear_regression(X_lin, y_lin)\n",
        "X_test = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "X_test_b = np.c_[np.ones((100, 1)), X_test]\n",
        "y_pred_lin = X_test_b.dot(w_lin)\n",
        "\n",
        "# 선형 회귀 시각화\n",
        "fig_lin = go.Figure()\n",
        "fig_lin.add_trace(go.Scatter(x=X_lin.squeeze(), y=y_lin.squeeze(), mode='markers', name='Data'))\n",
        "fig_lin.add_trace(go.Scatter(x=X_test.squeeze(), y=y_pred_lin.squeeze(), mode='lines', name='Prediction'))\n",
        "fig_lin.update_layout(title='Linear Regression', xaxis_title='x', yaxis_title='y')\n",
        "fig_lin.show()\n",
        "\n",
        "# --------------------------- #\n",
        "\n",
        "# 로지스틱 회귀용 샘플 데이터 생성\n",
        "X_log, y_log = make_classification(n_samples=200, n_features=1, n_redundant=0, n_informative=1,\n",
        "                                   n_clusters_per_class=1, flip_y=0.1, random_state=1)\n",
        "\n",
        "# 시그모이드 함수\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# 로지스틱 회귀 학습 함수\n",
        "def logistic_regression(X, y, lr=0.1, epochs=1000):\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    w = np.random.randn(X_b.shape[1], 1)\n",
        "    y = y.reshape(-1, 1)\n",
        "    for _ in range(epochs):\n",
        "        z = X_b.dot(w)\n",
        "        h = sigmoid(z)\n",
        "        gradients = 1 / X.shape[0] * X_b.T.dot(h - y)\n",
        "        w -= lr * gradients\n",
        "    return w\n",
        "\n",
        "# 학습 및 예측\n",
        "w_log = logistic_regression(X_log, y_log)\n",
        "X_range = np.linspace(X_log.min(), X_log.max(), 200).reshape(-1, 1)\n",
        "X_range_b = np.c_[np.ones((200, 1)), X_range]\n",
        "y_prob = sigmoid(X_range_b.dot(w_log))\n",
        "\n",
        "# 로지스틱 회귀 시각화\n",
        "fig_log = go.Figure()\n",
        "fig_log.add_trace(go.Scatter(x=X_log.squeeze(), y=y_log, mode='markers', name='Data', marker=dict(color='black')))\n",
        "fig_log.add_trace(go.Scatter(x=X_range.squeeze(), y=y_prob.squeeze(), mode='lines', name='Probability'))\n",
        "fig_log.update_layout(title='Logistic Regression', xaxis_title='x', yaxis_title='Probability')\n",
        "fig_log.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pl5LsyxNFEQi",
        "outputId": "7190d19e-d365-4609-c045-6c14053d88fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f2fed3e2-4b64-46d4-b135-ba6b71caff77\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f2fed3e2-4b64-46d4-b135-ba6b71caff77\")) {                    Plotly.newPlot(                        \"f2fed3e2-4b64-46d4-b135-ba6b71caff77\",                        [{\"mode\":\"markers\",\"name\":\"Data\",\"x\":[1.0976270078546495,1.430378732744839,1.2055267521432877,1.0897663659937937,0.8473095986778094,1.2917882261333122,0.875174422525385,1.7835460015641595,1.9273255210020586,0.7668830376515554,1.5834500761653292,1.057789839505809,1.1360891221878646,1.851193276585322,0.14207211639577388,0.17425859940308142,0.04043679488065144,1.665239691095876,1.556313501899701,1.7400242964936383,1.957236684465528,1.5983171284334472,0.9229587245058637,1.561058352572911,0.23654885173786644,1.2798420426550476,0.2867065748180928,1.8893378340991678,1.0436966435001434,0.8293238799810472,0.5291112242092539,1.5484673788684333,0.9123006644330971,1.136867897737297,0.037579600872710284,1.2352709941517541,1.2241914454448428,1.2338679937495138,1.8874961570292483,1.3636405982069668,0.719015801147572,0.8740639075986829,1.3952623918545297,0.12045094325853967,1.3335334308913354,1.3412757392363188,0.4207651221476818,0.2578525953097066,0.6308567018483677,0.7274215418852452,1.1403935408357593,0.8772030269246407,1.9767476761184524,0.20408962149605614,0.4177535121896694,0.3226190357699925,1.3062166509307969,0.5065832050795642,0.9326215457126126,0.4888511840032055,0.31793916729103944,0.22075028232861027,1.3126591789305468,0.2763659026972276,0.393164723360107,0.7374503413219282,1.6419864596958702,0.19420255158612254,1.6758898149976078,0.19219681578792613,1.9529189300267915,0.9373024032954032,1.9535221763806743,1.209691039490092,1.4785271587966033,0.07837558450864135,0.5656139251528192,0.2403931224263378,0.5922803950442899,0.2374554379084881,0.635966358787952,0.8285259890293399,0.12829499269756872,1.3849442387400397,1.1332029084131503,0.5307789818788908,1.0464961069333993,0.18788102151688335,1.1518929911123585,1.8585923951524281,0.6371379049026473,1.3348207599273634,0.26359572480878435,1.432654408237131,0.5788121858944022,0.36638272401423366,1.1730258696201663,0.040215092374987105,1.6578800584347262,0.009390952385094131],\"y\":[6.127731182780592,9.191962685188704,8.082242696160323,5.733055411704157,8.030180989829027,9.771253854430519,7.804302838735806,9.170713168880127,8.711223941495632,7.355100839885803,8.347173281522808,8.395814588899855,7.616542344640455,10.530218866239679,4.782582746361724,5.229348966401192,4.131810405362774,10.781589567193462,8.795852598402723,9.622062252925616,11.754860750452838,7.4471923241578954,5.498391175031857,9.652571765876745,3.536523150099439,9.783147313614435,4.446500743694531,8.920558690856746,9.054031956980815,7.968486431377566,7.454892633054332,9.551446794880686,5.875676308244588,9.320668646310924,3.84473543166675,8.508269378251658,8.619826304108276,7.546593888157707,10.276567841433824,9.013128466187426,6.533472934598345,5.522790932211854,8.484025349769645,5.6877387264626496,7.306032432942641,7.874192677381285,4.827141814721408,6.622821514408461,6.564864862557539,6.589726461896846,6.651264548061961,7.170858272065739,9.25591036769798,4.64409942276252,4.617414458190127,5.644290402256477,8.495240769407332,5.311450859660698,7.193871349799483,4.373492043279111,3.4625599091675126,5.101642548250368,8.104651032164169,5.464129144983789,7.562638944944263,7.1568305109561985,8.013137153643454,5.69962394285422,7.711762034481303,4.11500584254907,9.790515184755742,8.525249931535576,9.115811707093583,6.802634579811261,8.337128951964377,3.5716484671638162,6.8234776975649645,3.64124785891559,4.629372532721767,4.27454626898103,5.409866625671551,8.415110020905006,5.334305785018467,8.242383957605309,6.174173206409283,6.43669992203822,6.139272973410633,3.0188719677730385,8.643708765689377,9.892719797382133,6.832272538488761,8.32318993272511,5.647617786329045,7.646937631411247,4.702193715898742,5.780742690324328,6.715667944686658,3.43109549937476,8.518107671786836,4.045652016180339],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Prediction\",\"x\":[0.0,0.020202020202020204,0.04040404040404041,0.06060606060606061,0.08080808080808081,0.10101010101010102,0.12121212121212122,0.14141414141414144,0.16161616161616163,0.18181818181818182,0.20202020202020204,0.22222222222222224,0.24242424242424243,0.26262626262626265,0.2828282828282829,0.30303030303030304,0.32323232323232326,0.3434343434343435,0.36363636363636365,0.38383838383838387,0.4040404040404041,0.42424242424242425,0.4444444444444445,0.4646464646464647,0.48484848484848486,0.5050505050505051,0.5252525252525253,0.5454545454545455,0.5656565656565657,0.5858585858585859,0.6060606060606061,0.6262626262626263,0.6464646464646465,0.6666666666666667,0.686868686868687,0.7070707070707072,0.7272727272727273,0.7474747474747475,0.7676767676767677,0.787878787878788,0.8080808080808082,0.8282828282828284,0.8484848484848485,0.8686868686868687,0.888888888888889,0.9090909090909092,0.9292929292929294,0.9494949494949496,0.9696969696969697,0.98989898989899,1.0101010101010102,1.0303030303030305,1.0505050505050506,1.0707070707070707,1.090909090909091,1.1111111111111112,1.1313131313131315,1.1515151515151516,1.1717171717171717,1.191919191919192,1.2121212121212122,1.2323232323232325,1.2525252525252526,1.272727272727273,1.292929292929293,1.3131313131313131,1.3333333333333335,1.3535353535353536,1.373737373737374,1.393939393939394,1.4141414141414144,1.4343434343434345,1.4545454545454546,1.474747474747475,1.494949494949495,1.5151515151515154,1.5353535353535355,1.5555555555555556,1.575757575757576,1.595959595959596,1.6161616161616164,1.6363636363636365,1.6565656565656568,1.676767676767677,1.696969696969697,1.7171717171717173,1.7373737373737375,1.7575757575757578,1.777777777777778,1.7979797979797982,1.8181818181818183,1.8383838383838385,1.8585858585858588,1.878787878787879,1.8989898989898992,1.9191919191919193,1.9393939393939394,1.9595959595959598,1.97979797979798,2.0],\"y\":[4.222151077447219,4.282120118067441,4.342089158687664,4.402058199307887,4.46202723992811,4.521996280548333,4.581965321168555,4.6419343617887785,4.701903402409001,4.761872443029223,4.821841483649447,4.881810524269669,4.941779564889892,5.001748605510115,5.0617176461303375,5.121686686750561,5.181655727370783,5.241624767991006,5.301593808611229,5.3615628492314515,5.421531889851675,5.481500930471897,5.54146997109212,5.601439011712343,5.661408052332566,5.721377092952789,5.781346133573011,5.841315174193234,5.901284214813457,5.96125325543368,6.021222296053902,6.0811913366741255,6.141160377294348,6.20112941791457,6.261098458534794,6.321067499155017,6.3810365397752395,6.441005580395462,6.5009746210156845,6.560943661635908,6.620912702256131,6.680881742876354,6.740850783496576,6.8008198241167985,6.860788864737021,6.920757905357244,6.980726945977468,7.04069598659769,7.100665027217913,7.160634067838135,7.220603108458358,7.280572149078582,7.340541189698804,7.400510230319027,7.460479270939249,7.520448311559472,7.580417352179696,7.640386392799918,7.700355433420141,7.760324474040363,7.820293514660586,7.88026255528081,7.940231595901032,8.000200636521255,8.060169677141477,8.1201387177617,8.180107758381922,8.240076799002146,8.300045839622369,8.360014880242591,8.419983920862816,8.479952961483036,8.53992200210326,8.599891042723483,8.659860083343705,8.71982912396393,8.77979816458415,8.839767205204375,8.899736245824597,8.95970528644482,9.019674327065044,9.079643367685264,9.139612408305489,9.19958144892571,9.259550489545934,9.319519530166156,9.379488570786378,9.439457611406603,9.499426652026823,9.559395692647048,9.61936473326727,9.679333773887492,9.739302814507717,9.799271855127937,9.859240895748162,9.919209936368384,9.979178976988607,10.03914801760883,10.099117058229051,10.159086098849276],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Linear Regression\"},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f2fed3e2-4b64-46d4-b135-ba6b71caff77');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"81d91509-e6af-42e0-b19d-3adc5ada2e34\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"81d91509-e6af-42e0-b19d-3adc5ada2e34\")) {                    Plotly.newPlot(                        \"81d91509-e6af-42e0-b19d-3adc5ada2e34\",                        [{\"marker\":{\"color\":\"black\"},\"mode\":\"markers\",\"name\":\"Data\",\"x\":[1.1585687827873388,0.2718959947483668,1.113413801453454,1.0661647319500134,0.6502080554213938,-1.4893108143875182,-0.3613089020000094,-0.3547685058574802,0.8122314729525377,-1.3850154784718471,-0.388415606971516,1.2189400514565698,-1.7821499837399006,-0.3427774560316439,1.0802596317683186,1.451297699893781,-2.4741014931985026,-1.2172974132831953,-1.223210128006441,0.6918599455547385,-0.1766526979768428,-2.5017578232599678,0.5884998428736593,-1.0092319715916624,-0.44452519860928064,-0.9124090669670761,-0.6912900383987425,-0.767433624207948,-1.1952793891610232,-0.34331307410162337,1.0137228982599011,0.7662758942411304,-1.4888852157314814,0.9884336421834246,0.7124057155298011,0.9845133153209302,-1.4656081897349145,0.5616092527476721,-0.8554476620564166,0.10788393407391883,0.1840809447196199,1.3979104850237984,1.5730142865494623,1.1099791942888537,-1.2799598245990627,-0.36915344099767755,1.1052002268712005,-1.6821374201225214,-0.9629632369937582,0.6802984860162212,1.0619563802700218,1.5771514885354685,1.863486010391446,0.7806988567331802,0.8509519572040958,-1.6399226716652286,1.039168713253328,-0.8322704039916511,-1.4519551084711702,0.9146254775599701,-1.1522753022442633,0.42277318190743407,0.7156296023062305,-2.6777270249750638,0.9938259621491622,0.5482777363819258,-1.3677348604174489,1.0641612152329847,0.10335961199412202,0.5413729512889209,0.9834854661268495,0.6315933142736498,-1.146344373084935,1.0422211397972803,0.9724016703469579,0.7863946912639415,0.693824937814863,0.3023909574029162,-0.969227915313263,0.6999192749084976,-0.8650285889690013,0.8243792433541461,-0.16554350933534068,0.5309995902261084,-1.5446476581337452,0.8434753936694299,-0.5751516861554147,1.405826948972856,0.6059770675067917,-1.162068069407443,-1.0550886697803283,0.9511659174177793,-1.832848763284236,0.22309461565815425,-0.1260381889024591,0.8689638397123478,-0.7811881857263863,0.8047584800190075,-2.052699553473912,-1.549925063137647,0.9242727629472778,-1.2735672894338275,-1.801775484465299,-0.6438903687573672,0.8882325015310476,-0.5723758272422041,1.6725216569695922,-1.445945257958851,0.8756830730007866,-1.4984094808486252,1.3048170196625077,0.9399305516333409,0.900465496603752,-0.4911633641230093,0.5657430288363308,-0.8640044210847936,-1.0895819187126363,0.815383845679544,-1.2350288775172817,-1.8144732781293844,-0.9132475932090554,1.1018902879050636,1.0355188522548266,-0.39644054832569986,-0.17352871968851658,-0.6260952627920717,0.3245356329415343,-1.5548885147837508,-0.9682196849377633,0.9175485930510923,0.593194557029114,-0.8833395602800926,1.3382184800575558,-0.5500843246918263,0.6023026596920635,1.274901771202978,-1.2546564727175358,1.0944112002163457,0.8215515409495205,1.088175341872445,-1.125693069626638,1.3535836064119313,0.06581653514491781,0.758821387822842,-0.7247715327049892,0.20992750303277918,0.8888040615266275,0.8004235266569097,-0.4590803345548575,0.7373705366109837,-0.6337022995027684,-2.0179883768641074,-0.9436222719358666,1.025928543494075,0.7894944959209743,0.23372977675175632,-0.82912060012755,0.8549883284402471,1.1833813476393156,-0.7699151086481321,0.7579413298542264,1.4253060240384634,1.6589109841982026,-1.181780744653016,1.4362253648986316,1.4869595889047054,1.0087301081536135,-1.1398402255779414,-1.8023061008354562,-1.647044997859192,-0.7010892186651698,-0.8608304659196087,0.5278147040826887,-1.5041922331599533,0.9117663614297342,-0.7918185889210203,-1.25065518338865,-0.08671065769402664,-0.17508873165733596,-0.6133926835138495,0.7338755121140687,1.04838849194902,1.2141732074200533,0.8801282058117876,1.036082953385687,1.2211276948569536,-1.289216998681238,-1.2567756465735558,0.7188405536683962,-1.6161201409847714,1.388297354076879,0.6296011378095367,0.2244138981204009,-0.3212648881676555,1.2294212445820671,1.4653855726965905,0.8569065285859016,-0.9111973051610283,-1.4643436204177185,-1.5009206281773442],\"y\":[1,0,1,1,1,0,0,0,1,0,0,1,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,1,0,1,1,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,1,1,1,1,1,0,1,0,0,1,0,1,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,1,0,1,0,1,0,0,1,0,0,0,1,0,1,0,1,0,1,0,1,0,1,0,0,1,0,0,0,1,1,0,0,0,1,0,0,1,0,0,1,0,1,1,0,0,1,1,0,1,0,1,0,0,1,1,0,1,0,0,0,1,1,0,0,1,0,0,1,1,1,0,1,1,1,0,0,0,1,0,1,0,1,0,0,0,0,1,1,0,1,0,1,1,0,0,1,0,1,1,1,0,1,1,1,0,0,0],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Probability\",\"x\":[-2.6777270249750638,-2.654906858968197,-2.63208669296133,-2.609266526954463,-2.5864463609475963,-2.5636261949407295,-2.5408060289338623,-2.5179858629269956,-2.495165696920129,-2.472345530913262,-2.449525364906395,-2.426705198899528,-2.4038850328926613,-2.3810648668857946,-2.3582447008789273,-2.3354245348720606,-2.312604368865194,-2.2897842028583266,-2.26696403685146,-2.244143870844593,-2.221323704837726,-2.198503538830859,-2.1756833728239924,-2.1528632068171256,-2.130043040810259,-2.1072228748033917,-2.084402708796525,-2.061582542789658,-2.038762376782791,-2.015942210775924,-1.9931220447690574,-1.9703018787621904,-1.9474817127553234,-1.9246615467484567,-1.90184138074159,-1.879021214734723,-1.856201048727856,-1.8333808827209892,-1.8105607167141222,-1.7877405507072552,-1.7649203847003885,-1.7421002186935217,-1.7192800526866547,-1.6964598866797878,-1.673639720672921,-1.650819554666054,-1.6279993886591873,-1.6051792226523203,-1.5823590566454535,-1.5595388906385865,-1.5367187246317198,-1.5138985586248528,-1.491078392617986,-1.468258226611119,-1.445438060604252,-1.4226178945973853,-1.3997977285905183,-1.3769775625836516,-1.3541573965767846,-1.3313372305699178,-1.3085170645630508,-1.285696898556184,-1.262876732549317,-1.2400565665424503,-1.2172364005355834,-1.1944162345287164,-1.1715960685218496,-1.1487759025149826,-1.1259557365081159,-1.1031355705012489,-1.0803154044943821,-1.0574952384875151,-1.0346750724806484,-1.0118549064737814,-0.9890347404669146,-0.9662145744600477,-0.9433944084531807,-0.9205742424463139,-0.8977540764394469,-0.8749339104325802,-0.8521137444257132,-0.8292935784188464,-0.8064734124119795,-0.7836532464051127,-0.7608330803982457,-0.738012914391379,-0.715192748384512,-0.692372582377645,-0.6695524163707782,-0.6467322503639115,-0.6239120843570443,-0.6010919183501775,-0.5782717523433107,-0.555451586336444,-0.5326314203295768,-0.50981125432271,-0.48699108831584326,-0.46417092230897605,-0.4413507563021093,-0.41853059029524253,-0.3957104242883758,-0.37289025828150857,-0.3500700922746418,-0.32724992626777505,-0.3044297602609083,-0.2816095942540411,-0.2587894282471743,-0.23596926224030756,-0.21314909623344036,-0.1903289302265736,-0.16750876421970684,-0.14468859821284008,-0.12186843220597288,-0.09904826619910612,-0.07622810019223936,-0.053407934185372596,-0.030587768178505392,-0.007767602171638632,0.015052563835228128,0.03787272984209533,0.06069289584896209,0.08351306185582885,0.10633322786269561,0.12915339386956282,0.15197355987642958,0.17479372588329634,0.1976138918901631,0.2204340578970303,0.24325422390389706,0.2660743899107638,0.288894555917631,0.3117147219244978,0.33453488793136454,0.3573550539382313,0.3801752199450985,0.40299538595196527,0.42581555195883203,0.4486357179656988,0.471455883972566,0.49427604997943275,0.5170962159862995,0.5399163819931667,0.5627365480000335,0.5855567140069002,0.608376880013767,0.6311970460206342,0.654017212027501,0.6768373780343677,0.6996575440412345,0.7224777100481017,0.7452978760549684,0.7681180420618352,0.7909382080687024,0.8137583740755692,0.8365785400824359,0.8593987060893027,0.8822188720961699,0.9050390381030367,0.9278592041099034,0.9506793701167702,0.9734995361236374,0.9963197021305041,1.019139868137371,1.041960034144238,1.0647802001511049,1.0876003661579716,1.1104205321648384,1.1332406981717056,1.1560608641785723,1.178881030185439,1.2017011961923059,1.224521362199173,1.2473415282060398,1.2701616942129066,1.2929818602197738,1.3158020262266406,1.3386221922335073,1.3614423582403745,1.3842625242472408,1.407082690254108,1.4299028562609752,1.4527230222678416,1.4755431882747088,1.498363354281576,1.5211835202884423,1.5440036862953095,1.5668238523021758,1.589644018309043,1.6124641843159102,1.6352843503227765,1.6581045163296437,1.680924682336511,1.7037448483433772,1.7265650143502445,1.7493851803571117,1.772205346363978,1.7950255123708452,1.8178456783777115,1.8406658443845787,1.863486010391446],\"y\":[0.00007195603532771435,0.00007753230381085114,0.00008354067186964541,0.00009001461666397124,0.00009699020807990803,0.00010450630937954973,0.00011260479335474841,0.00012133077517884785,0.00013073286324180635,0.0001408634293523125,0.00015177889979610675,0.00016354006885324805,0.00017621243649908584,0.00018986657214481223,0.0002045785064143669,0.0002204301531057656,0.0002375097636474475,0.00025591241653467,0.00027574054441821967,0.0002971045017186071,0.00032012317585434976,0.0003449246454039501,0.0003716468887687577,0.00040043854716906,0.00043145974608970757,0.0004648829795954316,0.0005008940622609681,0.0005396931538084788,0.0005814958619157433,0.0006265344290545882,0.000675059009641331,0.0007273390442309288,0.0007836647379655001,0.0008443486509971152,0.0009097274091455892,0.0009801635436256341,0.0010560474692851963,0.0011377996114391984,0.0012258726920608188,0.0013207541868065923,0.0014229689651021511,0.0015330821263022266,0.0016517020457609255,0.0017794836455053424,0.0019171319050950626,0.00206540562916969,0.002225121489132318,0.00239715835738407,0.002582461953507142,0.002782049822783389,0.00299701666842234,0.003228540059844632,0.0034778865403093284,0.0037464181580685488,0.004035599446058657,0.0043470048758686985,0.004682326812332741,0.005043383995538051,0.005432130577283153,0.005850665739009313,0.00630124391790887,0.006786285667217249,0.0073083891755457335,0.007870342468420633,0.008475136312860702,0.009125977842731938,0.009826304918638031,0.010579801231085758,0.011390412149442634,0.012262361311592272,0.013200167939984159,0.014208664858741832,0.015293017173383792,0.01645874155925646,0.01771172608668179,0.019058250489775073,0.02050500676156265,0.022059119930090118,0.023728168838316927,0.025520206714413494,0.027443781278299228,0.029507954084607116,0.03172231875152026,0.03409701766896114,0.03664275671841474,0.039370817470368684,0.042293066254301244,0.04542195942093326,0.048770544037992344,0.05235245318030201,0.05618189489434137,0.06027363383878532,0.06464296452879417,0.06930567504650013,0.07427800002750895,0.07957656169831953,0.08521829772818733,0.09122037467768067,0.0976000858822586,0.10437473271039284,0.1115614882901154,0.1191772430134093,0.12723843141205515,0.1357608403578477,0.14475939897915058,0.15424795120669124,0.16423901246294906,0.17474351268576244,0.18577052861687068,0.19732700907297257,0.20941749772681376,0.2220438587281863,0.23520501125228135,0.24889667973235716,0.263111167067616,0.27783715844571505,0.29305956353347273,0.3087594046243771,0.32491375785119064,0.3414957537525621,0.3584746423170093,0.3758159261286801,0.39348156344177626,0.4114302409720281,0.4296177139930754,0.44799720906020807,0.46651988246351533,0.48513532545285604,0.5037921054915028,0.5224383313862466,0.5410222291924027,0.5594927153597882,0.5777999536966936,0.5958958833763444,0.6137347063550541,0.6312733241446411,0.6484717157918066,0.6652932510561346,0.681704935030879,0.6976775827024146,0.7131859240896964,0.7282086425539944,0.7427283505510179,0.756731508463919,0.7702082931808698,0.7831524237606095,0.7955609518778339,0.8074340247868866,0.8187746283270786,0.8295883170630599,0.8398829380586844,0.8496683540719773,0.8589561711781389,0.8677594750179484,0.8760925790650718,0.8839707875354483,0.8914101748460818,0.8984273828836847,0.9050394367744876,0.9112635793589083,0.9171171241685676,0.9226173263750287,0.9277812709242086,0.9326257768806697,0.9371673168742384,0.9414219504594872,0.945405270158644,0.9491323589528305,0.9526177580082342,0.9558754434665813,0.958918811187642,0.9617606684007008,0.964413231298046,0.9668881276833113,0.969196403868303,0.9713485350917759,0.9733544388108933,0.975223490289721,0.9769645399782815,0.9785859322399509,0.9800955250440545,0.9815007102943573,0.9828084345127922,0.9840252196414063,0.9851571837643898,0.9862100615864395,0.9871892245339629,0.9880997003720555,0.9889461922531368,0.9897330971329423,0.9904645235065507,0.9911443084315988,0.9917760338180667,0.9923630419742784,0.9929084504072977,0.9934151658829242,0.9938858977562008,0.9943231705879276,0.9947293360662744,0.9951065842553632],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Logistic Regression\"},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"Probability\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('81d91509-e6af-42e0-b19d-3adc5ada2e34');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}